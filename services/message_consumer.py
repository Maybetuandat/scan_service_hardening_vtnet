import logging
import threading
from typing import Dict, Any, Optional
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor

from config.redis_pubsub import get_pubsub_manager, RedisPubSubManager

from schemas.scan_message import ScanInstanceMessage, ScanResponseMessage
from services.scan_service import ScanService # Import ScanService

logger = logging.getLogger(__name__)

class MessageConsumerService:
    _instance: Optional['MessageConsumerService'] = None
    _lock = threading.Lock()
    
    def __init__(self):
        if MessageConsumerService._instance is not None:
            raise RuntimeError("Use get_instance() instead")
        
        self.pubsub_manager = get_pubsub_manager() # L·∫•y singleton PubSubManager
        self.is_running = False
        self.consumer_thread = None
        self.stop_event = threading.Event()
        
        # T·∫°o ThreadPoolExecutor d√πng chung cho to√†n b·ªô ·ª©ng d·ª•ng, gi·ªõi h·∫°n 10 lu·ªìng
        self.max_workers = 10
        self.thread_pool = ThreadPoolExecutor(max_workers=self.max_workers)
        self._warm_up_threads() # Kh·ªüi ƒë·ªông c√°c lu·ªìng
        
        # Kh·ªüi t·∫°o ScanService v·ªõi thread_pool chung v√† pubsub_manager
        # ScanService KH√îNG c√≤n c·∫ßn db_engine
        self.scan_service = ScanService(self.thread_pool, self.pubsub_manager) 
        
        self.stats = {
            "total_messages_received": 0,
            "scan_requests_processed": 0,
            "scan_responses_received": 0, # Th√™m th·ªëng k√™ response
            "fix_requests_processed": 0,
            "fix_responses_received": 0, # Th√™m th·ªëng k√™ response
            "errors": 0,
            "started_at": None,
            "last_message_at": None,
            "active_scan_tasks": 0, 
            "pending_scan_tasks": 0 
        }
        
        logger.info("‚úÖ Consumer initialized (with integrated ScanService and ThreadPool, DB-less for worker)")
    
    def _warm_up_threads(self):
        def dummy_task():
            import time
            time.sleep(0.01)  
            return "warmed"
        futures = [self.thread_pool.submit(dummy_task) for _ in range(self.max_workers)]
        for future in futures:
            future.result()
        logger.info(f"Thread pool warmed up with {self.max_workers} threads")

    @classmethod
    def get_instance(cls): 
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = MessageConsumerService()
        return cls._instance
    
    def start(self):
        if self.is_running:
            logger.warning("‚ö†Ô∏è Consumer already running.")
            return
        
        logger.info("üöÄ Starting consumer...")
        
        # ƒêƒÉng k√Ω l·∫Øng nghe c·∫£ request v√† response
        self.pubsub_manager.subscribe_scan_requests()
        self.pubsub_manager.subscribe_scan_responses() # M·ªõi
        self.pubsub_manager.subscribe_fix_requests()
        self.pubsub_manager.subscribe_fix_responses() # M·ªõi
        
        self.is_running = True
        self.stop_event.clear()
        self.stats["started_at"] = datetime.now().isoformat()
        
        self.consumer_thread = threading.Thread(
            target=self._consume_messages,
            daemon=True
        )
        self.consumer_thread.start()
        
        logger.info("‚úÖ Consumer started and listening for messages!")
    
    def stop(self, timeout=5):
        if not self.is_running:
            logger.info("üõë Consumer not running.")
            return
        
        logger.info("üõë Stopping consumer...")
        self.stop_event.set()
        self.is_running = False
        
        if self.consumer_thread:
            self.consumer_thread.join(timeout=timeout)
        
        # ƒê√≥ng thread pool m·ªôt c√°ch an to√†n
        self.thread_pool.shutdown(wait=True) 
        
        self.pubsub_manager.close()
        logger.info("‚úÖ Consumer stopped.")
    
    def _consume_messages(self):
        logger.info("üëÇ Listening for messages from Redis Pub/Sub...")
        
        try:
            # pubsub_manager.listen_for_messages gi·ªù yield dict {"channel": ..., "message": ...}
            for message_envelope in self.pubsub_manager.listen_for_messages():
                if self.stop_event.is_set():
                    logger.info("Stopping message consumption as stop event is set.")
                    break
                
                channel = message_envelope["channel"]
                message_payload = message_envelope["message"]
                
                self._handle_message_from_broker(channel, message_payload)
                
                self.stats["total_messages_received"] += 1
                self.stats["last_message_at"] = datetime.now().isoformat()
                
        except Exception as e:
            logger.critical(f"‚ùå CRITICAL Error in message consumption loop: {e}", exc_info=True)
            self.stats["errors"] += 1
    
    def _handle_message_from_broker(self, channel: str, message_payload: Dict[str, Any]):
        """
        Callback ƒë·ªÉ x·ª≠ l√Ω message nh·∫≠n ƒë∆∞·ª£c t·ª´ Redis Pub/Sub.
        Ph√¢n t√≠ch message v√† g·ª≠i t·ªõi ScanService ho·∫∑c log response.
        """
        try:
            message_type = message_payload.get("type")
            data = message_payload.get("data", {}) # Data n·∫±m trong key 'data'
            
            if channel == self.pubsub_manager.settings.REDIS_CHANNEL_SCAN_REQUEST:
                self.stats["scan_requests_processed"] += 1
                # Chuy·ªÉn ƒë·ªïi payload th√†nh ScanInstanceMessage Pydantic model
                scan_message = ScanInstanceMessage(**data) # data l√† n·ªôi dung c·ªßa ScanInstanceMessage
                self._log_scan_request(scan_message)
                
                # G·ª≠i t√°c v·ª• qu√©t t·ªõi ScanService
                self.scan_service.submit_scan_task(scan_message)
                # Note: stats["pending_scan_tasks"] s·∫Ω ƒë∆∞·ª£c c·∫≠p nh·∫≠t b·ªüi thread_pool n·ªôi b·ªô
                
            elif channel == self.pubsub_manager.settings.REDIS_CHANNEL_SCAN_RESPONSE:
                self.stats["scan_responses_received"] += 1
                scan_response = ScanResponseMessage(**data) # data l√† n·ªôi dung c·ªßa ScanResponseMessage
                self._log_scan_response(scan_response)
                
            elif channel == self.pubsub_manager.settings.REDIS_CHANNEL_FIX_REQUEST:
                self.stats["fix_requests_processed"] += 1
                self._log_fix_request(data) # Gi·∫£ ƒë·ªãnh data l√† dict cho fix request
                
            elif channel == self.pubsub_manager.settings.REDIS_CHANNEL_FIX_RESPONSE:
                self.stats["fix_responses_received"] += 1
                self._log_fix_response(data) # Gi·∫£ ƒë·ªãnh data l√† dict cho fix response
                
            else:
                logger.warning(f"‚ö†Ô∏è Consumer received message from unknown channel: {channel}. Message type: {message_type}")
                
        except Exception as e:
            logger.error(f"‚ùå Error handling message from channel {channel}: {e}", exc_info=True)
            self.stats["errors"] += 1

    def _log_scan_request(self, scan_message: ScanInstanceMessage):
        logger.info("\n" + "="*80)
        logger.info("üì® RECEIVED SCAN REQUEST FROM BROKER")
        logger.info("="*80)
        logger.info(f"Scan Request ID: {scan_message.scan_request_id}")
        logger.info(f"Instance ID:  {scan_message.instance_id}")
        logger.info(f"Instance Name:{scan_message.instance_name}")
        logger.info(f"User ID:      {scan_message.user_id}")
        logger.info(f"Workload ID:  {scan_message.workload_id}")
        logger.info(f"Rules Count:  {len(scan_message.rules)}")
        logger.info(f"Timestamp:    {scan_message.timestamp.isoformat()}")
        logger.info("="*80 + "\n")
    
    def _log_scan_response(self, scan_response: ScanResponseMessage):
        logger.info("\n" + "#"*80)
        logger.info("‚úÖ RECEIVED SCAN RESPONSE FROM BROKER")
        logger.info("#"*80)
        logger.info(f"Scan Request ID: {scan_response.scan_request_id}")
        logger.info(f"Instance ID:  {scan_response.instance_id}")
        logger.info(f"Instance Name:{scan_response.instance_name}")
        logger.info(f"Overall Status: {scan_response.status.upper()}")
        logger.info(f"Total Rules: {scan_response.total_rules}, Passed: {scan_response.rules_passed}, Failed: {scan_response.rules_failed}")
        if scan_response.detail_error:
            logger.error(f"Error Detail: {scan_response.detail_error}")
        logger.info("-" * 80)
        for rr in scan_response.rule_results:
            logger.info(f"  Rule {rr.rule_id} ({rr.status.upper()}): {rr.message}")
            if rr.details_error:
                logger.debug(f"    Error: {rr.details_error}")
            if rr.output:
                logger.debug(f"    Output: {rr.output}")
        logger.info("#"*80 + "\n")

    def _log_fix_request(self, data: Dict):
        import json
        logger.info("\n" + "="*80)
        logger.info("üîß RECEIVED FIX REQUEST FROM BROKER")
        logger.info("="*80)
        logger.info(f"Job ID:       {data.get('job_id')}")
        logger.info(f"User:         {data.get('username')} (ID: {data.get('user_id')})")
        logger.info(f"Instances:    {data.get('instance_ids')}")
        logger.info(f"Rules:        {data.get('rule_ids')}")
        logger.info(f"Time:         {data.get('timestamp')}")
        logger.info("="*80 + "\n")

    def _log_fix_response(self, data: Dict):
        import json
        logger.info("\n" + "#"*80)
        logger.info("üîß RECEIVED FIX RESPONSE FROM BROKER")
        logger.info("#"*80)
        logger.info(f"Job ID:       {data.get('job_id')}")
        logger.info(f"Status:       {data.get('status')}")
        logger.info(f"Time:         {data.get('timestamp')}")
        logger.info("#"*80 + "\n")
    
    def get_stats(self):
        # C·∫≠p nh·∫≠t s·ªë l∆∞·ª£ng t√°c v·ª• ƒëang ch·∫°y/ch·ªù
        # Note: self.thread_pool._work_queue.qsize() v√† _pending_work_items 
        # l√† c√°c thu·ªôc t√≠nh n·ªôi b·ªô v√† c√≥ th·ªÉ kh√¥ng ph·∫£n √°nh ch√≠nh x√°c 100%
        # s·ªë t√°c v·ª• ƒëang ch·∫°y/ch·ªù trong m·ªçi th·ªùi ƒëi·ªÉm, nh∆∞ng cung c·∫•p m·ªôt ∆∞·ªõc t√≠nh.
        self.stats["active_scan_tasks"] = self.thread_pool._work_queue.qsize() # T√°c v·ª• ƒë√£ ƒë∆∞·ª£c submit v√† ƒëang ch·ªù
        # S·ªë lu·ªìng th·ª±c s·ª± ƒëang b·∫≠n c√≥ th·ªÉ l·∫•y t·ª´ self.thread_pool._threads n·∫øu mu·ªën ph·ª©c t·∫°p h∆°n,
        # nh∆∞ng qsize() th∆∞·ªùng l√† ƒë·ªß ƒë·ªÉ bi·ªÉu th·ªã t·∫£i.
        
        return {**self.stats, "is_running": self.is_running}